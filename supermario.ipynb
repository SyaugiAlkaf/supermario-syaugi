{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951f880-961b-41e3-9e26-3b919c4b5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym_super_mario_bros nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a28f03c-0b21-4bd9-811d-7847868f6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8986b6c2-0b02-4ab2-82a9-55f0349f697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saugi\\Documents\\randomProjects\\venv\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\saugi\\Documents\\randomProjects\\venv\\lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0', apply_api_compatibility=True, render_mode=\"human\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1548d0a6-1f5a-44a7-962a-52e926243908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import layers, models\n",
    "from skimage.color import rgb2gray  # Import rgb2gray from the correct module\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c0714c-0c9a-44e0-b438-1807d9e80eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Deep Q-Network (DQN) model\n",
    "def build_dqn(input_shape, num_actions):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=input_shape),\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(num_actions)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d14c959-9eca-4c36-99a8-a61a535e07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "observation_shape = (84, 84, 1)  # Preprocessed observation shape\n",
    "num_actions = env.action_space.n\n",
    "learning_rate = 0.001\n",
    "discount_factor = 0.99\n",
    "exploration_max = 1.0\n",
    "exploration_min = 0.1\n",
    "exploration_decay = 0.995\n",
    "batch_size = 32\n",
    "memory_size = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e7e911-f909-4277-93e7-453c810a3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DQN and target DQN\n",
    "dqn = build_dqn(observation_shape, num_actions)\n",
    "target_dqn = build_dqn(observation_shape, num_actions)\n",
    "target_dqn.set_weights(dqn.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f61e90-777f-49e0-a7e7-b84bea8454c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess observation function\n",
    "def preprocess_observation(observation):\n",
    "    gray_observation = np.mean(observation, axis=2, keepdims=True)  # Convert to grayscale\n",
    "    resized_observation = resize(gray_observation, (84, 84))\n",
    "    return resized_observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59579a9-bf54-4e91-8cf7-a2679338b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_fn = tf.keras.losses.Huber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a403599a-9576-4535-814b-00f74006fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay memory\n",
    "replay_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fbac69-6f3e-4b6b-ba1f-13f0c4da3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration strategy\n",
    "def exploration_strategy(step):\n",
    "    return exploration_min + (exploration_max - exploration_min) * np.exp(-exploration_decay * step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce4ecf3-7a81-490e-9e12-d3e8940edede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_replay():\n",
    "    if len(replay_memory) < batch_size:\n",
    "        return\n",
    "    \n",
    "    batch = random.sample(replay_memory, batch_size)\n",
    "    \n",
    "    states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "    for experience in batch:\n",
    "        state, action, reward, next_state, done = experience\n",
    "        preprocessed_state = preprocess_observation(state)\n",
    "        preprocessed_next_state = preprocess_observation(next_state)\n",
    "        \n",
    "        states.append(preprocessed_state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        next_states.append(preprocessed_next_state)\n",
    "        dones.append(done)\n",
    "    \n",
    "    states = np.array(states)\n",
    "    next_states = np.array(next_states)\n",
    "    \n",
    "    q_values = dqn.predict(states)\n",
    "    q_values_next = target_dqn.predict(next_states)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        if dones[i]:\n",
    "            q_values[i][actions[i]] = rewards[i]\n",
    "        else:\n",
    "            q_values[i][actions[i]] = rewards[i] + discount_factor * np.max(q_values_next[i])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_q_values = dqn(states)\n",
    "        loss = loss_fn(q_values, predicted_q_values)\n",
    "    gradients = tape.gradient(loss, dqn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3590662d-33d4-4df1-9fc9-23486c5dffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saugi\\Documents\\randomProjects\\venv\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "C:\\Users\\saugi\\Documents\\randomProjects\\venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m total_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_steps \u001b[38;5;241m>\u001b[39m batch_size:\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mexperience_replay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m     target_dqn\u001b[38;5;241m.\u001b[39mset_weights(dqn\u001b[38;5;241m.\u001b[39mget_weights())\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mexperience_replay\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experience \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m      9\u001b[0m     state, action, reward, next_state, done \u001b[38;5;241m=\u001b[39m experience\n\u001b[1;32m---> 10\u001b[0m     preprocessed_state \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     preprocessed_next_state \u001b[38;5;241m=\u001b[39m preprocess_observation(next_state)\n\u001b[0;32m     13\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(preprocessed_state)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mpreprocess_observation\u001b[1;34m(observation)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_observation\u001b[39m(observation):\n\u001b[1;32m----> 3\u001b[0m     gray_observation \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     resized_observation \u001b[38;5;241m=\u001b[39m resize(gray_observation, (\u001b[38;5;241m84\u001b[39m, \u001b[38;5;241m84\u001b[39m))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized_observation\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\randomProjects\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3461\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3465\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\randomProjects\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:165\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 165\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "total_steps = 0\n",
    "for episode in range(10000):  # You can adjust the number of episodes\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    while True:\n",
    "        exploration_prob = exploration_strategy(total_steps)\n",
    "        if np.random.rand() < exploration_prob:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            q_values = dqn.predict(np.expand_dims(state, axis=0))\n",
    "            action = np.argmax(q_values)\n",
    "        \n",
    "        next_state, reward, done, _, __ = env.step(action)\n",
    "        next_state = preprocess_observation(next_state)\n",
    "        \n",
    "        replay_memory.append((state, action, reward, next_state, done))\n",
    "        if len(replay_memory) > memory_size:\n",
    "            replay_memory.pop(0)\n",
    "        \n",
    "        state = next_state\n",
    "        total_steps += 1\n",
    "        \n",
    "        if total_steps > batch_size:\n",
    "            experience_replay()\n",
    "        \n",
    "        if total_steps % 100 == 0:\n",
    "            target_dqn.set_weights(dqn.get_weights())\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    print(f\"Episode {episode+1}, Reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea722d90-de27-4100-bb3f-c02695dc4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b854db2-511f-46a9-9a14-ecf5302d84c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a7380-c8f6-4a4c-aa77-f8cae9881a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
